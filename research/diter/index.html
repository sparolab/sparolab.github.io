<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DiTer: Diverse Terrain and Multimodal Dataset for Field Robot Navigation in Outdoor Environments">
  <meta name="keywords" content="Field Robot Dataset">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DiTer: Diverse Terrain and Multimodal Dataset for Field Robot Navigation in Outdoor Environments</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DiTer: Diverse Terrain and Multimodal Dataset for Field Robot Navigation in Outdoor Environments</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">IEEE Sensors Letters</span>            
          </div>
          <div class="is-size-3 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=ZAO6skQAAAAJ&hl=ko">Seokhwan Jeong</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=t5UEbooAAAAJ&hl=ko">Hogyun Kim</a><sup>1</sup>,</span>
            <span class="author-block">
              and <a href="https://scholar.google.com/citations?user=W5MOKWIAAAAJ&hl=ko">Younggun Cho</a><sup>1*</sup>
            </span>            
          </div>

          <div class="is-size-3 publication-authors">
            <span class="author-block"><sup>1</sup>Spatial AI and Robotics (SPARO) Lab, Inha University, South Korea</span>            
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10416213"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://ieeexplore.ieee.org/abstract/document/10416213"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=i-2FwYKT5ss"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/image.png">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">TL;DR  Multimodal, multi-terrain dataset for navigation in challenging field environments!</span>
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Field robots require autonomy in diverse environments to navigate and map their surroundings efficiently. However, the lack of diverse and comprehensive datasets hinders the evaluation
            and development of autonomous field robots. To address this challenge, we present a multimodal,
            multisession, and diverse terrain dataset for the ground mapping of field robots. First of all, we utilize
            a quadrupedal robot as a base platform to collect the dataset. Also, the dataset includes various
            terrain types, such as sandy roads, vegetation, and sloping terrain. It comprises RGB-D camera for
            ground, RGB camera, thermal camera, light detection and ranging (LiDAR), inertial measurement
            unit (IMU), and global positioning system (GPS). In addition, we provide not only the reference
            trajectories of each dataset but also the global map by leveraging LiDAR-based simultaneous localization and mapping (SLAM) algorithms. Also, we assess our dataset from a terrain perspective and generate the
            fusion maps, such as thermal-LiDAR and RGB-LiDAR maps to exploit the information beyond the visible spectrum.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/sparolab/diter" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
