- title: "PoLaRIS Dataset: A Maritime Object Detection and Tracking Dataset in Pohang Canal"
  abstract: >
    Maritime environments often present hazardous situations due to factors such as moving ships or buoys, which become obstacles under the influence of waves. 
    In such challenging conditions, the ability to detect and track potentially hazardous objects is critical for the safe navigation of marine robots. 
    To address the scarcity of comprehensive datasets capturing these dynamic scenarios, we introduce a new multimodal dataset that includes image and point-wise annotations of maritime hazards. 
    Our dataset provides detailed ground truth for obstacle detection and tracking, including objects as small as 10×10 pixels, which are crucial for maritime safety. 
    To validate the dataset’s effectiveness as a reliable benchmark, we conducted evaluations using various methodologies, including state-of-the-art (SOTA) techniques for object detection and tracking. 
    These evaluations are expected to contribute to performance improvements, particularly in the complex maritime environment. 
    To the best of our knowledge, this is the first dataset offering multi-modal annotations specifically tailored to maritime environments.
  session: Marine Robotics VI / Thursday, 11:30-11:35 / Paper ThCT7.4 
  page_link: /research/polaris/
  image: /img/research/polaris.gif

- title: "DiTer++: Diverse Terrain and Multi-modal Dataset for Multi-Robot SLAM in Multi-session Environments"
  abstract: >
    We encounter large-scale environments where both structured and unstructured spaces coexist, such as on campuses. 
    In this environment, lighting conditions and dynamic objects change constantly. 
    To tackle the challenges of large-scale mapping under such conditions, we introduce DiTer++, a diverse terrain and multi-modal dataset designed for multi-robot SLAM in multi-session environments. 
    According to our datasets' scenarios, Agent-A and Agent-B scan the area designated for efficient large-scale mapping day and night, respectively. 
    Also, we utilize legged robots for terrain-agnostic traversing. 
    To generate the ground-truth of each robot, we first build the survey-grade prior map. 
    Then, we remove the dynamic objects and outliers from the prior map and extract the trajectory through scan-to-map matching.
  session: SLAM VI / Thursday, 10:10-10:15 / Paper ThBT2.4	
  page_link: /research/diter_plus/
  image: /img/research/diter_plus.png

- title: "ReFeree: Radar-Based Lightweight and Robust Localization Using Feature and Free Space"
  abstract: >
    Place recognition plays an important role in achieving robust long-term autonomy. 
    Real-world robots face a wide range of weather conditions (e.g. overcast, heavy rain, and snowing) and most sensors (i.e. camera, LiDAR) essentially functioning within or near-visible electromagnetic waves are sensitive to adverse weather conditions, making reliable localization difficult. 
    In contrast, radar is gaining traction due to long electromagnetic waves, which are less affected by environmental changes and weather independence. 
    In this work, we propose a radar-based lightweight and robust place recognition. 
    We achieve rotational invariance and lightweight by selecting a one-dimensional ringshaped description and robustness by mitigating the impact of false detection utilizing opposite noise characteristics between free space and feature. 
    In addition, the initial heading can be estimated, which can assist in building a SLAM pipeline that combines odometry and registration, which takes into account onboard computing. 
    The proposed method was tested for rigorous validation across various scenarios (i.e. single session, multi-session, and different weather conditions). 
    In particular, we validate our descriptor achieving reliable place recognition performance through the results of extreme environments that lacked structural information such as an OORD dataset. 
    Our supplementary materials and code are available on publication.
  session: Localization IV / Wednesday, 11:35-11:40 / Paper WeCT17.5
  page_link: /research/referee/
  image: /img/research/referee.png

- title: "Narrowing your FOV with SOLiD: Spatially Organized and Lightweight Global Descriptor for FOV-constrained LiDAR Place Recognition"
  abstract: >
    We often encounter limited FOV situations due to various factors such as sensor fusion or sensor mount in real-world robot navigation. 
    However, the limited FOV interrupts the generation of descriptions and impacts place recognition adversely. 
    Therefore, we suffer from correcting accumulated drift errors in a consistent map using LiDAR-based place recognition with limited FOV. 
    Thus, in this letter, we propose a robust LiDAR-based place recognition method for handling narrow FOV scenarios. 
    The proposed method establishes spatial organization based on the range-elevation bin and azimuth-elevation bin to represent places. 
    In addition, we achieve a robust place description through reweighting based on vertical direction information. 
    Based on these representations, our method enables addressing rotational changes and determining the initial heading. 
    Additionally, we designed a lightweight and fast approach for the robot's onboard autonomy. 
    For rigorous validation, the proposed method was tested across various LiDAR place recognition scenarios (i.e., single-session, multi-session, and multi-robot scenarios). 
    To the best of our knowledge, we report the first method to cope with the restricted FOV.
  session: Perception I / Wednesday, 10:00-10:05 / Paper WeBT7.2
  page_link: /research/solid/
  image: /img/research/solid.gif

- title: "SKiD-SLAM: Robust, Lightweight, and Distributed Multi-Robot LiDAR SLAM in Resource-Constrained Field Environments"
  abstract: >
    Robust localization in degenerate environments such as construction sites remains challenging due to frequent visual degradation and intermittent range sensing. 
    To address this challenge, we propose a visual Simultaneous Localization and Mapping (SLAM) framework that tightly integrates visual-inertial odometry (VIO), visual loop closure, and Ultra-Wideband (UWB) range measurements through a factor graph optimization. 
    The proposed system introduces an interpolated range factor, fully utilizing sparse and asynchronous UWB data by leveraging continuous-time pose interpolation. 
    We evaluate the method on the public dataset under simulated degenerate scenarios, including visual degradation and partial UWB signal loss. 
    Experimental results demonstrate that the proposed method significantly reduces drift and maintains accurate global localization, even under severe sensor degradation.
  session: Workshop on Field Robotics / Monday, 8:30-17:30 
  page_link: /research/skid_slam/
  image: /img/research/skid_slam.gif

- title: "Robust Visual SLAM with Auxiliary Range Factor for Degenerate Construction Environments"
  abstract: >
    Robust localization in degenerate environments such as construction sites remains challenging due to frequent visual degradation and intermittent range sensing. 
    To address this challenge, we propose a visual Simultaneous Localization and Mapping (SLAM) framework that tightly integrates visual-inertial odometry (VIO), visual loop closure, and Ultra-Wideband (UWB) range measurements through a factor graph optimization. 
    The proposed system introduces an interpolated range factor, fully utilizing sparse and asynchronous UWB data by leveraging continuous-time pose interpolation. 
    We evaluate the method on the public dataset under simulated degenerate scenarios, including visual degradation and partial UWB signal loss. 
    Experimental results demonstrate that the proposed method significantly reduces drift and maintains accurate global localization, even under severe sensor degradation.
  session: Workshop on Future of Construction / Monday, 8:30-17:30
  page_link: /research/icra_2025/vir-construction
  image: /research/icra_2025/static/images/vir-construction.png